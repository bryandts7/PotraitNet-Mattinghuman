# config.yaml

# Data parameters
data_root: ./new_archive/
file_root: ./select_data/
model_root: ./drive/MyDrive/easy_output/
# Model parameters
istrain: True
task: 'seg'
datasetlist: ['easypotrait']
input_height: 224 # the height of input images
input_width: 224 # the width of input images

video: False # if exp_args.video=True, add prior channel for input images
prior_prob: 0.5 # the probability to set empty prior channel

addEdge: False # whether to add boundary auxiliary loss 
edgeRatio: 0.1 # the weight of boundary auxiliary loss
stability: True # whether to add consistency constraint loss
use_kl: True # whether to use KL loss in consistency constraint loss
temperature: 1 # temperature in consistency constraint loss
alpha: 2 # the weight of consistency constraint loss


# input normalization parameters
padding_color: 128
img_scale: 1
img_mean: [103.94, 116.78, 123.68] # BGR order, image mean
img_val: [0.017, 0.017, 0.017] # BGR order, image val

init: False # whether to use pretrain model to init portraitnet
resume: False # whether to continue training

useUpsample: True # if exp_args.useUpsample==True, use nn.Upsample in decoder, else use nn.ConvTranspose2d
useDeconvGroup: False # if exp_args.useDeconvGroup==True, set groups=input_channel in nn.ConvTranspose2d